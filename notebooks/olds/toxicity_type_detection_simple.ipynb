{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity Type Detection\n",
    "\n",
    "Author: Douglas Trajano ([LinkedIn](https://www.linkedin.com/in/douglas-trajano/) | [GitHub](https://github.com/DougTrajano))\n",
    "\n",
    "In this notebook, we will train a model to detect the toxicity labels of the comments in the OLID-BR dataset.\n",
    "\n",
    "We will use the pre-trained BERT model from the [Hugging Face Transformers](https://huggingface.co/transformers/) library.\n",
    "\n",
    "[neuralmind/bert-base-portuguese-cased · Hugging Face](https://huggingface.co/neuralmind/bert-base-portuguese-cased)\n",
    "\n",
    "## Index\n",
    "\n",
    "The notebook will be divided into seperate sections to provide a organized walk through for the training process.\n",
    "\n",
    "1. [Setup environment](#setup-environment)\n",
    "2. [Download dataset](#download-dataset)\n",
    "3. [Data preprocessing](#data-preprocessing)\n",
    "4. [Prepare training session](#prepare-training-session)\n",
    "5. [Hyperparameter tuning](#hyperparameter-tuning)\n",
    "6. [Training with best hyperparameters](#training-with-best-hyperparameters)\n",
    "7. [Evaluation](#evaluation)\n",
    "8. [Register best model](#register-best-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment\n",
    "\n",
    "In this section, we will prepare the environment to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if str(Path(\".\").absolute().parent) not in sys.path:\n",
    "    sys.path.append(str(Path(\".\").absolute().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Initialize the env vars\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from torch.cuda import is_available\n",
    "from sklearn.metrics import classification_report\n",
    "from simpletransformers.classification import (\n",
    "    MultiLabelClassificationModel,\n",
    "    MultiLabelClassificationArgs\n",
    ")\n",
    "\n",
    "from src.utils import (\n",
    "    compute_pos_weight,\n",
    "    download_dataset,\n",
    "    flatten\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "_logger = logging.getLogger(\"transformers\")\n",
    "_logger.setLevel(logging.WARNING)\n",
    "\n",
    "mlflow.set_experiment(\"toxicity-type-detection\")\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "mlflow.set_tag(\"model\", \"BERT\")\n",
    "mlflow.set_tag(\"dataset\", \"OLID-BR\")\n",
    "mlflow.set_tag(\"framework\", \"simpletransformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "In this section, we will download the OLID-BR dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading OLID-BR from Kaggle.\n",
      "Train shape: (4765, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>is_targeted</th>\n",
       "      <th>targeted_type</th>\n",
       "      <th>toxic_spans</th>\n",
       "      <th>health</th>\n",
       "      <th>ideology</th>\n",
       "      <th>insult</th>\n",
       "      <th>lgbtqphobia</th>\n",
       "      <th>other_lifestyle</th>\n",
       "      <th>physical_aspects</th>\n",
       "      <th>profanity_obscene</th>\n",
       "      <th>racism</th>\n",
       "      <th>religious_intolerance</th>\n",
       "      <th>sexism</th>\n",
       "      <th>xenophobia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430b13705cf34e13b74bc999425187c3</td>\n",
       "      <td>USER USER é muito bom. USER ^^ E claro a equip...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c779826dc43f460cb18e8429ca443477</td>\n",
       "      <td>Pior do que adolescentezinhas de merda...são p...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e64148caa4474fc79298e01d0dda8f5e</td>\n",
       "      <td>USER Toma no cu é vitamina como tu e tua prima.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc66b54eeec24607a67e2259134a1cdd</td>\n",
       "      <td>Muito bom, pena a circunstâncias serem ruins, ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[119, 120, 121, 122, 123, 124, 125, 126, 127, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a3d7839456ae4258a70298fcf637952e</td>\n",
       "      <td>Podia ter beijo também, pra ver se o homofóbic...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  430b13705cf34e13b74bc999425187c3   \n",
       "1  c779826dc43f460cb18e8429ca443477   \n",
       "2  e64148caa4474fc79298e01d0dda8f5e   \n",
       "3  cc66b54eeec24607a67e2259134a1cdd   \n",
       "4  a3d7839456ae4258a70298fcf637952e   \n",
       "\n",
       "                                                text is_offensive is_targeted  \\\n",
       "0  USER USER é muito bom. USER ^^ E claro a equip...          NOT         UNT   \n",
       "1  Pior do que adolescentezinhas de merda...são p...          OFF         UNT   \n",
       "2    USER Toma no cu é vitamina como tu e tua prima.          OFF         TIN   \n",
       "3  Muito bom, pena a circunstâncias serem ruins, ...          OFF         UNT   \n",
       "4  Podia ter beijo também, pra ver se o homofóbic...          OFF         UNT   \n",
       "\n",
       "  targeted_type                                        toxic_spans  health  \\\n",
       "0           NaN                                                NaN   False   \n",
       "1           NaN  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   False   \n",
       "2           GRP  [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...   False   \n",
       "3           NaN  [119, 120, 121, 122, 123, 124, 125, 126, 127, ...   False   \n",
       "4           NaN  [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...   False   \n",
       "\n",
       "   ideology  insult  lgbtqphobia  other_lifestyle  physical_aspects  \\\n",
       "0     False   False        False            False             False   \n",
       "1     False    True        False            False             False   \n",
       "2     False    True        False            False             False   \n",
       "3     False    True        False            False             False   \n",
       "4     False    True        False            False             False   \n",
       "\n",
       "   profanity_obscene  racism  religious_intolerance  sexism  xenophobia  \n",
       "0              False   False                  False   False       False  \n",
       "1               True   False                  False    True       False  \n",
       "2               True   False                  False   False       False  \n",
       "3              False   False                  False   False       False  \n",
       "4              False   False                  False   False       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = download_dataset([\"train.csv\", \"test.csv\"])\n",
    "\n",
    "train_df = dataset[\"train.csv\"]\n",
    "test_df = dataset[\"test.csv\"]\n",
    "\n",
    "del dataset\n",
    "\n",
    "mlflow.log_param(\"train_shape\", train_df.shape)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (1589, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>is_targeted</th>\n",
       "      <th>targeted_type</th>\n",
       "      <th>toxic_spans</th>\n",
       "      <th>health</th>\n",
       "      <th>ideology</th>\n",
       "      <th>insult</th>\n",
       "      <th>lgbtqphobia</th>\n",
       "      <th>other_lifestyle</th>\n",
       "      <th>physical_aspects</th>\n",
       "      <th>profanity_obscene</th>\n",
       "      <th>racism</th>\n",
       "      <th>religious_intolerance</th>\n",
       "      <th>sexism</th>\n",
       "      <th>xenophobia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da19df36730945f08df3d09efa354876</td>\n",
       "      <td>USER Adorei o comercial também Jesus. Só achei...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 6...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80f1a8c981864887b13963fed1261acc</td>\n",
       "      <td>Cara isso foi muito babaca geral USER conhece ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2f67025f913e4a6292e3d000d9e2b5a8</td>\n",
       "      <td>Se vc for porco, folgado e relaxado, você não ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>738ccd4476784f47af3a5a6cfdda4695</td>\n",
       "      <td>Se fosse um sniper ia ser louco</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[26, 27, 28, 29, 30]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e0064da693bd4c9e90ce8e6db8bd3bbb</td>\n",
       "      <td>USER é o meu saco USER USER USER</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[13, 14, 15, 16]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  da19df36730945f08df3d09efa354876   \n",
       "1  80f1a8c981864887b13963fed1261acc   \n",
       "2  2f67025f913e4a6292e3d000d9e2b5a8   \n",
       "3  738ccd4476784f47af3a5a6cfdda4695   \n",
       "4  e0064da693bd4c9e90ce8e6db8bd3bbb   \n",
       "\n",
       "                                                text is_offensive is_targeted  \\\n",
       "0  USER Adorei o comercial também Jesus. Só achei...          OFF         UNT   \n",
       "1  Cara isso foi muito babaca geral USER conhece ...          OFF         TIN   \n",
       "2  Se vc for porco, folgado e relaxado, você não ...          OFF         UNT   \n",
       "3                    Se fosse um sniper ia ser louco          OFF         UNT   \n",
       "4                   USER é o meu saco USER USER USER          OFF         UNT   \n",
       "\n",
       "  targeted_type                                        toxic_spans  health  \\\n",
       "0           NaN  [52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 6...   False   \n",
       "1           GRP  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   False   \n",
       "2           NaN  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   False   \n",
       "3           NaN                               [26, 27, 28, 29, 30]   False   \n",
       "4           NaN                                   [13, 14, 15, 16]   False   \n",
       "\n",
       "   ideology  insult  lgbtqphobia  other_lifestyle  physical_aspects  \\\n",
       "0     False    True        False            False             False   \n",
       "1     False    True        False            False             False   \n",
       "2     False    True        False            False             False   \n",
       "3     False    True        False            False              True   \n",
       "4     False    True        False            False             False   \n",
       "\n",
       "   profanity_obscene  racism  religious_intolerance  sexism  xenophobia  \n",
       "0               True   False                  False   False       False  \n",
       "1              False   False                  False   False       False  \n",
       "2              False   False                  False   False       False  \n",
       "3              False   False                  False   False       False  \n",
       "4               True   False                  False   False       False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.log_param(\"test_shape\", test_df.shape)\n",
    "\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "In this section, we will preprocess the dataset to be used in the training process.\n",
    "\n",
    "We will filter only the comments with the toxicity labels and also remove the unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4272, 16)\n",
      "Test shape: (1438, 16)\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess the dataset.\n",
    "\n",
    "    Args:\n",
    "    - df: The dataset to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "    - The preprocessed dataset.\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        # Filter only offensive comments\n",
    "        df = df[df[\"is_offensive\"] == \"OFF\"]\n",
    "\n",
    "        # Remove religious_intolerance that has only one  sample\n",
    "        if \"religious_intolerance\" in df.columns:\n",
    "            df.drop(\"religious_intolerance\", axis=1, inplace=True)\n",
    "\n",
    "        # Filter only offensive comments with at least one toxicity label\n",
    "        df = df.loc[df.select_dtypes(\"bool\").sum(axis=1).ge(1)]\n",
    "\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "toxicity_labels = [\n",
    "    \"health\",\n",
    "    \"ideology\",\n",
    "    \"insult\",\n",
    "    \"lgbtqphobia\",\n",
    "    \"other_lifestyle\",\n",
    "    \"physical_aspects\",\n",
    "    \"profanity_obscene\",\n",
    "    \"racism\",\n",
    "    \"sexism\",\n",
    "    \"xenophobia\"\n",
    "]\n",
    "\n",
    "train_df = preprocessing(train_df)\n",
    "test_df = preprocessing(test_df)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"text\"].values\n",
    "y_train = train_df[toxicity_labels].astype(int).values\n",
    "\n",
    "X_test = test_df[\"text\"].values\n",
    "y_test = test_df[toxicity_labels].astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training session\n",
    "\n",
    "In this section, we will prepare the training session, defining the training parameters and computing the class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_seq_length': 1084,\n",
       " 'model_name': 'neuralmind/bert-base-portuguese-cased',\n",
       " 'model_type': 'bert',\n",
       " 'num_train_epochs': 30,\n",
       " 'num_train_epochs_per_child': 3,\n",
       " 'seed': 1993,\n",
       " 'use_cuda': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_seq_length\": len(max(X_train, key=len)),\n",
    "    \"model_name\": \"neuralmind/bert-base-portuguese-cased\",\n",
    "    \"model_type\": \"bert\",\n",
    "    \"num_train_epochs\": 30,\n",
    "    \"num_train_epochs_per_child\": 3,\n",
    "    \"seed\": 1993,\n",
    "    \"use_cuda\": is_available()\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will compute the class weights to be used in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = compute_pos_weight(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import Any, Dict, List, Union\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class ToxicityTypeDetection(BaseEstimator):\n",
    "    def __init__(self,\n",
    "                 model_type: str = \"bert\",\n",
    "                 model_name: str = \"neuralmind/bert-base-portuguese-cased\",\n",
    "                 use_cuda: bool = True,\n",
    "                 args: MultiLabelClassificationArgs = MultiLabelClassificationArgs()):\n",
    "\n",
    "        self.model_type = model_type\n",
    "        self.model_name = model_name\n",
    "        self.use_cuda = use_cuda\n",
    "        self.args = args\n",
    "        self.model = None\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.model.args.__dict__\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self.model.args, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def fit(self,\n",
    "            X: List[str],\n",
    "            y: List[List[int]] | np.ndarray,\n",
    "            metrics: Dict[str, callable] = {}, pos_weights = None) -> None:\n",
    "\n",
    "        # define num_labels\n",
    "        if isinstance(y, np.ndarray):\n",
    "            num_labels = y.shape[1]\n",
    "        else:\n",
    "            num_labels = len(y[0])\n",
    "\n",
    "        data = self._prepare_data(X, y)\n",
    "\n",
    "        # Create a ClassificationModel\n",
    "        self.model = MultiLabelClassificationModel(\n",
    "            model_type=self.model_type,\n",
    "            model_name=self.model_name,\n",
    "            num_labels=num_labels,\n",
    "            args=self.args,\n",
    "            pos_weight=pos_weights,\n",
    "            use_cuda=self.use_cuda)\n",
    "\n",
    "        # Train the model\n",
    "        self.model.train_model(\n",
    "            train_df=data,\n",
    "            eval_df=data,\n",
    "            **metrics\n",
    "        )\n",
    "\n",
    "    def _predict(self, X: List[str] | np.ndarray) -> List[List[int]]:\n",
    "        predictions, raw_outputs = self.model.predict(X)\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, X: Union[str, List[str], np.ndarray]) -> List[List[int]]:\n",
    "        if isinstance(X, str):\n",
    "            return self._predict([X])\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            return self._predict(X.tolist())\n",
    "        else:\n",
    "            return self._predict(X)\n",
    "\n",
    "    def predict_proba(self, X: List[str]):\n",
    "        predictions, raw_outputs = self.model.predict(X)\n",
    "        return raw_outputs\n",
    "\n",
    "    def score(self, X, y, metrics: Dict[str, callable] = {}) -> Dict[str, Any]:\n",
    "        data = self._prepare_data(X, y)\n",
    "        result, model_outputs, wrong_predictions = self.model.eval_model(\n",
    "            eval_df=data,\n",
    "            **metrics\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def _prepare_data(self, X, y):\n",
    "        data = []\n",
    "        for x, _y in zip(X, y):\n",
    "            data.append([x, _y])\n",
    "\n",
    "        data = pd.DataFrame(data)\n",
    "        data.columns = [\"text\", \"labels\"]\n",
    "        return data\n",
    "\n",
    "    def _delete_folders(\n",
    "            folders: List[str] = [\"cache_dir\", \"outputs\", \"runs\"]):\n",
    "        \"\"\"Clean simpletransformers folders.\n",
    "\n",
    "        Args:\n",
    "        - folders: list of folders to clean\n",
    "        \"\"\"\n",
    "        for folder in folders:\n",
    "            if os.path.exists(folder):\n",
    "                shutil.rmtree(folder, ignore_errors=True)\n",
    "\n",
    "    def load_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scores(scores: Dict[str, Dict[str, float]]) -> Dict[str, float | int]:\n",
    "    \"\"\"Format scores to be logged in mlflow.\n",
    "\n",
    "    Args:\n",
    "    - scores: classification report scores\n",
    "\n",
    "    Returns:\n",
    "    - formatted_scores: formatted scores\n",
    "    \"\"\"\n",
    "    # Flatten the score dict\n",
    "    scores = flatten(scores)\n",
    "\n",
    "    # Remove whitespaces and \"-\" from keys\n",
    "    scores = {k.replace(\" \", \"_\").replace(\"-\", \"_\"): v for k, v in scores.items()}\n",
    "\n",
    "    # Remove \"_support\" items\n",
    "    scores = {k: v for k, v in scores.items() if not k.endswith(\"_support\")}\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Using the [Optuna](https://optuna.org/) library, we will perform a hyperparameter tuning to find the best hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"use_cuda\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-04 14:40:30,475]\u001b[0m A new study created in memory with name: no-name-8c7f4967-8402-46cd-a690-79d4f32790b5\u001b[0m\n",
      "c:\\Python310\\lib\\site-packages\\optuna\\progress_bar.py:49: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a99714db8e4dc1af5952dfaf7244b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-04 14:40:31,686 WARNING Connection pool is full, discarding connection: txshmzqv7b.us-east-1.awsapprunner.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: txshmzqv7b.us-east-1.awsapprunner.com. Connection pool size: 10\n",
      "2022-11-04 14:40:31,717 WARNING Connection pool is full, discarding connection: txshmzqv7b.us-east-1.awsapprunner.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: txshmzqv7b.us-east-1.awsapprunner.com. Connection pool size: 10\n",
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf50291445543729791838d7741db54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a889f7a81174bab9f4d628b944db0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4272 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    with mlflow.start_run(nested=True):\n",
    "        learning_rate = trial.suggest_float(\n",
    "            \"learning_rate\", 1e-6, 1e-2)\n",
    "        \n",
    "        adam_epsilon = trial.suggest_float(\n",
    "            \"adam_epsilon\", 1e-8, 1e-1)\n",
    "        \n",
    "        polynomial_decay_schedule_lr_end = trial.suggest_float(\n",
    "            \"polynomial_decay_schedule_lr_end\", 1e-7, 1e-2)\n",
    "\n",
    "        polynomial_decay_schedule_power = trial.suggest_float(\n",
    "            \"polynomial_decay_schedule_power\", 0.1, 1.0)\n",
    "        \n",
    "        mlflow.log_params(trial.params)\n",
    "        \n",
    "        model = ToxicityTypeDetection(\n",
    "            model_type=params[\"model_type\"],\n",
    "            model_name=params[\"model_name\"],\n",
    "            use_cuda=params[\"use_cuda\"],\n",
    "            args=MultiLabelClassificationArgs(\n",
    "                num_train_epochs=params[\"num_train_epochs_per_child\"],\n",
    "                manual_seed=params[\"seed\"],\n",
    "                max_seq_length=params[\"max_seq_length\"],\n",
    "                learning_rate=learning_rate,\n",
    "                adam_epsilon=adam_epsilon,\n",
    "                polynomial_decay_schedule_lr_end=polynomial_decay_schedule_lr_end,\n",
    "                polynomial_decay_schedule_power=polynomial_decay_schedule_power,\n",
    "                overwrite_output_dir=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            pos_weights=pos_weights\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        result = model.score(X_test, y_test)\n",
    "\n",
    "        scores = format_scores(\n",
    "            classification_report(\n",
    "                y_test, model.predict(X_test),\n",
    "                target_names=toxicity_labels,\n",
    "                output_dict=True, zero_division=0\n",
    "            )\n",
    "        )\n",
    "\n",
    "        mlflow.log_metrics(result)\n",
    "        mlflow.log_metrics(scores)\n",
    "\n",
    "        return result[\"LRAP\"]\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=20,\n",
    "    n_jobs=-1,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {trial.number}\")\n",
    "\n",
    "# E.g. {'x': 2.002108042}\n",
    "print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ToxicityTypeDetection(\n",
    "    model_type=params[\"model_type\"],\n",
    "    model_name=params[\"model_name\"],\n",
    "    use_cuda=params[\"use_cuda\"],\n",
    "    args=MultiLabelClassificationArgs(\n",
    "        num_train_epochs=params[\"num_train_epochs\"],\n",
    "        manual_seed=params[\"seed\"],\n",
    "        max_seq_length=params[\"max_seq_length\"],\n",
    "        learning_rate=trial.params[\"learning_rate\"],\n",
    "        adam_epsilon=trial.params[\"adam_epsilon\"],\n",
    "        polynomial_decay_schedule_lr_end=trial.params[\"polynomial_decay_schedule_lr_end\"],\n",
    "        polynomial_decay_schedule_power=trial.params[\"polynomial_decay_schedule_power\"],\n",
    "        overwrite_output_dir=True\n",
    "    )\n",
    ")\n",
    "\n",
    "detector.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    pos_weights=pos_weights\n",
    ")\n",
    "\n",
    "# mlflow.log_params(params)\n",
    "# mlflow.log_params(trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detector.score(X_test, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = detector.predict(X_test)\n",
    "\n",
    "scores = format_scores(\n",
    "    classification_report(\n",
    "        y_test, detector.predict(X_test),\n",
    "        target_names=toxicity_labels,\n",
    "        output_dict=True, zero_division=0\n",
    "    )\n",
    ")\n",
    "\n",
    "# mlflow.log_metrics(result)\n",
    "# mlflow.log_metrics(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=toxicity_labels,\n",
    "        digits=4, zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.pytorch.log_model(\n",
    "#     pytorch_model=detector.model.model,\n",
    "#     artifact_path=\"model\",\n",
    "#     conda_env=\"conda.yaml\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

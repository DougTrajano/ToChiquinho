---
title: Toxic Comment Classification
summary: Detects if the text is toxic or not.
---

Toxic Comment Classification is a method that detects if the text is toxic or not.

## Overview

**Input:** Text in Brazilian Portuguese

**Output:** Binary classification (toxic or not toxic)

**Model architecture:** BERT fine-tuned for binary classification

**Dataset:** [OLID-BR](https://dougtrajano.github.io/olid-br/)

## Usage

PENDING

## Limitations

The following factors may degrade the modelâ€™s performance.

- The model was trained on Brazilian Portuguese texts, so it may not work well on other Portuguese dialects.
- The model was trained on texts from social media, so it may not work well on other types of texts.

PENDING

## Trade-offs

Sometimes models exhibit performance issues under particular circumstances. In this section, we'll discuss situations in which you might discover that the model performs less than optimally, and should plan accordingly.

PENDING

## Performance

## Provide Feedback

If you have any feedback on this model, please [open an issue](https://github.com/DougTrajano/ToChiquinho/issues/new) on GitHub.

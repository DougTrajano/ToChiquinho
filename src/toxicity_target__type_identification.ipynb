{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity Target Type Identification\n",
    "\n",
    "![SageMaker](https://img.shields.io/badge/SageMaker-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)\n",
    "\n",
    "This notebook is a part of [ToChiquinho](https://dougtrajano.github.io/ToChiquinho/) project, which trains a model to classify the type of a given targeted toxic comment.\n",
    "\n",
    "We used the [OLID-BR](https://dougtrajano.github.io/olid-br/) dataset as the training data. The possible values are:\n",
    "\n",
    "- `IND`: Individual\n",
    "- `GRP`: Group\n",
    "- `OTH`: Other\n",
    "\n",
    "The model is trained using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "\n",
    "- [Setup](#Setup)\n",
    "- [Prepare the data](#Prepare-the-data)\n",
    "  - [Uploading the data to S3](#Uploading-the-data-to-S3)\n",
    "- [Training process](#Training-process)\n",
    "  - [Define the estimator](#Define-the-estimator)\n",
    "  - [Hyperparameter tuning](#Hyperparameter-tuning)\n",
    "  - [Training best model](#Training-best-model)\n",
    "- [Documentation](#Documentation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section, we will import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, you can change the parameters to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotebookArguments(num_train_epochs=10, early_stopping_patience=2, batch_size=8, validation_split=0.2, seed=1993, mlflow_experiment_name='toxicity-target-type-identification', mlflow_tags='{\"project\": \"ToChiquinho\", \"dataset\": \"OLID-BR\", \"model_type\": \"bert\", \"problem_type\": \"multi_class_classification\"}')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ml.arguments import NotebookArguments\n",
    "from ml.utils import remove_checkpoints\n",
    "\n",
    "params = NotebookArguments(\n",
    "    mlflow_tracking_uri=os.environ.get(\"MLFLOW_TRACKING_URI\"),\n",
    "    mlflow_experiment_name=\"toxicity-target-type-identification\",\n",
    "    mlflow_tracking_username=os.environ.get(\"MLFLOW_TRACKING_USERNAME\"),\n",
    "    mlflow_tracking_password=os.environ.get(\"MLFLOW_TRACKING_PASSWORD\"),\n",
    "    mlflow_tags={\n",
    "        \"project\": \"ToChiquinho\",\n",
    "        \"dataset\": \"OLID-BR\",\n",
    "        \"model_type\": \"bert\",\n",
    "        \"problem_type\": \"multi_class_classification\"\n",
    "    },\n",
    "    sagemaker_execution_role_arn=os.environ.get(\"SAGEMAKER_EXECUTION_ROLE_ARN\"),\n",
    "    aws_profile_name=os.environ.get(\"AWS_PROFILE\")\n",
    ")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session(\n",
    "    boto_session=boto3.Session(profile_name=params.aws_profile_name)\n",
    ")\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = f\"ToChiquinho/{params.mlflow_experiment_name}\"\n",
    "\n",
    "if params.sagemaker_execution_role_arn is None:\n",
    "    params.sagemaker_execution_role_arn = sagemaker.get_execution_role(sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "In this section, we will prepare the data to be used in the training process.\n",
    "\n",
    "We will download OLID-BR dataset from [HuggingFace Datasets](https://huggingface.co/datasets/olidbr), process it and upload it to S3 to be used in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration dougtrajano--olid-br-f83aad8215e23434\n",
      "Found cached dataset parquet (C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30ee4be76ff42d7966023e73d7cfa9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dougtrajano/olid-br\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-038bf56f76cc4a37.arrow\n",
      "Loading cached processed dataset at C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-43b90f5725815a2a.arrow\n",
      "Loading cached processed dataset at C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-e0c368268074a955.arrow\n",
      "Loading cached processed dataset at C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-c6cac6994c04a29c.arrow\n",
      "Loading cached split indices for dataset at C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-c291d599f9a3c0ad.arrow and C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-7ed0f881b9ffcc0b.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 946\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 568\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "from typing import Union\n",
    "\n",
    "def prepare_dataset(\n",
    "    dataset: Union[datasets.Dataset, datasets.DatasetDict],\n",
    "    test_size: float = 0.2,\n",
    "    seed: int = 42\n",
    ") -> Union[datasets.Dataset, datasets.DatasetDict]:\n",
    "\n",
    "    # Filter only rows with is_offensive = \"OFF\" and is_targeted = \"TIN\"\n",
    "    dataset = dataset.filter(\n",
    "        lambda example: example[\"is_offensive\"] == \"OFF\" \n",
    "        and example[\"is_targeted\"] == \"TIN\"\n",
    "        and example[\"targeted_type\"] is not None\n",
    "    )\n",
    "\n",
    "    # Filter only \"text\" and \"is_targeted\" columns\n",
    "    dataset = dataset.remove_columns(\n",
    "        [\n",
    "            col for col in dataset[\"train\"].column_names if col not in [\"text\", \"targeted_type\"]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.rename_column(\"targeted_type\", \"label\")\n",
    "\n",
    "    # Replace \"TIN\": 1 and \"UNT\": 0\n",
    "    def replace_labels(example):\n",
    "        if example[\"label\"] == \"IND\":\n",
    "            example[\"label\"] = 0\n",
    "        elif example[\"label\"] == \"GRP\":\n",
    "            example[\"label\"] = 1\n",
    "        elif example[\"label\"] == \"OTH\":\n",
    "            example[\"label\"] = 2\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid label: {example['label']}\")\n",
    "        return example\n",
    "\n",
    "    dataset = dataset.map(replace_labels)\n",
    "\n",
    "    train_dataset = dataset[\"train\"].train_test_split(\n",
    "        test_size=test_size,\n",
    "        shuffle=True,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    dataset[\"train\"] = train_dataset[\"train\"]\n",
    "    dataset[\"validation\"] = train_dataset[\"test\"]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = prepare_dataset(\n",
    "    dataset,\n",
    "    test_size=params.validation_split,\n",
    "    seed=params.seed\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-5285d4ed43b61082.arrow\n",
      "Loading cached processed dataset at C:/Users/trajano/.cache/huggingface/datasets/dougtrajano___parquet/dougtrajano--olid-br-f83aad8215e23434/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-0ff545f03babdb1e.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location.\n",
    "\n",
    "The return value inputs identifies the location -- we will use later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-215993976552/ToChiquinho/toxicity-target-type-identification/data\n"
     ]
    }
   ],
   "source": [
    "# inputs = sagemaker_session.upload_data(\n",
    "#     path=\"data\",\n",
    "#     bucket=bucket_name,\n",
    "#     key_prefix=f\"{prefix}/data\"\n",
    "# )\n",
    "\n",
    "inputs = \"s3://sagemaker-us-east-1-215993976552/ToChiquinho/toxicity-target-type-identification/data\"\n",
    "\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training session\n",
    "\n",
    "In this section, we will run the training process.\n",
    "\n",
    "To use Amazon SageMaker to run Docker containers, we need to provide a Python script for the container to run. In our case, all the code is in the `ml` folder, including the `train.py` script.\n",
    "\n",
    "We will start doing a hyperparameter tuning process to find the best hyperparameters for our model.\n",
    "\n",
    "Then, we will train the model using the best hyperparameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFlow run ID: 070bc1bab2ee4eaeacd9313bbece6bb2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "print(f\"MLFlow run ID: {mlflow.active_run().info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the estimator\n",
    "\n",
    "We will use the `sagemaker.pytorch.PyTorch` class to define our estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "checkpoint_s3_uri = f\"s3://{bucket_name}/{prefix}/checkpoints\"\n",
    "\n",
    "instance_type = \"ml.g4dn.xlarge\" # 4 vCPUs, 16 GB RAM, 1 x NVIDIA T4 16GB GPU - $ 0.736 per hour\n",
    "# instance_type = \"ml.g4dn.2xlarge\" # 8 vCPUs, 32 GB RAM, 1 x NVIDIA T4 16GB GPU - $ 0.94 per hour\n",
    "# instance_type = \"ml.g5.xlarge\" # 4 vCPUs, 16 GB RAM, 1 x NVIDIA A10G 24GB GPU - $ 1.408 per hour\n",
    "# instance_type = \"ml.g5.2xlarge\" # 8 vCPUs, 32 GB RAM, 1 x NVIDIA A10G 24GB GPU - $ 1.515 per hour\n",
    "# instance_type = \"ml.g5.4xlarge\" # 16 vCPUs, 64 GB RAM, 2 x NVIDIA A10G 24GB GPU - $ 2.03 per hour\n",
    "# instance_type = \"ml.g5.8xlarge\" # 32 vCPUs, 128 GB RAM, 4 x NVIDIA A10G 24GB GPU - $ 3.06 per hour\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"ml\",\n",
    "    container_log_level=logging.DEBUG,\n",
    "    role=params.sagemaker_execution_role_arn,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.12.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    use_spot_instances=True,\n",
    "    max_wait=10800,\n",
    "    max_run=10800,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    environment={\n",
    "        \"MLFLOW_TRACKING_URI\": params.mlflow_tracking_uri,\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": params.mlflow_experiment_name,\n",
    "        \"MLFLOW_TRACKING_USERNAME\": params.mlflow_tracking_username,\n",
    "        \"MLFLOW_TRACKING_PASSWORD\": params.mlflow_tracking_password,\n",
    "        \"MLFLOW_TAGS\": params.mlflow_tags,\n",
    "        \"MLFLOW_RUN_ID\": mlflow.active_run().info.run_id,\n",
    "        \"MLFLOW_FLATTEN_PARAMS\": \"True\",\n",
    "        \"HF_MLFLOW_LOG_ARTIFACTS\": \"True\",\n",
    "        \"WANDB_DISABLED\": \"True\"\n",
    "    },\n",
    "    hyperparameters={\n",
    "        ## If you want to test the code, uncomment the following lines to use smaller datasets\n",
    "        # \"max_train_samples\": 50,\n",
    "        # \"max_val_samples\": 50,\n",
    "        # \"max_test_samples\": 50,\n",
    "        \"num_train_epochs\": params.num_train_epochs,\n",
    "        \"early_stopping_patience\": params.early_stopping_patience,\n",
    "        \"eval_dataset\": \"validation\",\n",
    "        \"batch_size\": params.batch_size,\n",
    "        \"seed\": params.seed\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_params(\n",
    "    {\n",
    "        \"instance_type\": estimator.instance_type,\n",
    "        \"instance_count\": estimator.instance_count,\n",
    "        \"early_stopping_patience\": params.early_stopping_patience\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our training job before hyperparameter tuning, we will run it with a small number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "We will use the `sagemaker.tuner.HyperparameterTuner` class to run a hyperparameter tuning process.\n",
    "\n",
    "We use MLflow to track the training process, so we can analyze the results through the MLflow UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workaround for boto/boto3/issues/3488 issue\n",
    "\n",
    "Due to the issue [Estimator.environment not using in SageMaker.Client.create_hyper_parameter_tuning_job() · Issue #3488 · boto/boto3](https://github.com/boto/boto3/issues/3488), we need to include our environment variables in the `hyperparameters` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in estimator.environment.items():\n",
    "    if k != \"MLFLOW_TAGS\":\n",
    "        estimator._hyperparameters[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "estimator._hyperparameters.pop(\"max_train_samples\", None)\n",
    "estimator._hyperparameters.pop(\"max_val_samples\", None)\n",
    "estimator._hyperparameters.pop(\"max_test_samples\", None)\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    max_jobs=18,\n",
    "    max_parallel_jobs=3,\n",
    "    objective_type=\"Maximize\",\n",
    "    objective_metric_name=\"eval_f1\",\n",
    "    metric_definitions=[\n",
    "        {\n",
    "            \"Name\": \"eval_f1\",\n",
    "            \"Regex\": \"eval_f1_weighted: ([0-9\\\\.]+)\"\n",
    "        }\n",
    "    ],\n",
    "    hyperparameter_ranges={\n",
    "        \"learning_rate\": ContinuousParameter(1e-5, 1e-3),\n",
    "        \"weight_decay\": ContinuousParameter(0.0, 0.1),\n",
    "        \"adam_beta1\": ContinuousParameter(0.8, 0.999),\n",
    "        \"adam_beta2\": ContinuousParameter(0.8, 0.999),\n",
    "        \"adam_epsilon\": ContinuousParameter(1e-8, 1e-6),\n",
    "        \"label_smoothing_factor\": ContinuousParameter(0.0, 0.1),\n",
    "        \"optim\": CategoricalParameter(\n",
    "            [\n",
    "                \"adamw_hf\",\n",
    "                \"adamw_torch\",\n",
    "                \"adamw_apex_fused\",\n",
    "                \"adafactor\"\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker tuning job name: pytorch-training-221209-0011\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(inputs, wait=False)\n",
    "\n",
    "params.sagemaker_tuning_job_name = tuner.latest_tuning_job.name\n",
    "\n",
    "print(f\"SageMaker tuning job name: {params.sagemaker_tuning_job_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pytorch-training-221209-0011-010-d474d283</td>\n",
       "      <td>0.794327</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pytorch-training-221209-0011-012-713a2cab</td>\n",
       "      <td>0.789217</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pytorch-training-221209-0011-017-26c875ea</td>\n",
       "      <td>0.788787</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pytorch-training-221209-0011-005-d9f53221</td>\n",
       "      <td>0.783829</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch-training-221209-0011-018-bbc1a967</td>\n",
       "      <td>0.782722</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pytorch-training-221209-0011-011-0a4772df</td>\n",
       "      <td>0.780891</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pytorch-training-221209-0011-009-67fb584b</td>\n",
       "      <td>0.780385</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pytorch-training-221209-0011-001-ff4aab66</td>\n",
       "      <td>0.774016</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pytorch-training-221209-0011-006-da6d3b9e</td>\n",
       "      <td>0.771442</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pytorch-training-221209-0011-013-14b6c947</td>\n",
       "      <td>0.768171</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pytorch-training-221209-0011-015-61ec86e2</td>\n",
       "      <td>0.767598</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pytorch-training-221209-0011-008-90a1fb3f</td>\n",
       "      <td>0.766771</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pytorch-training-221209-0011-016-0c5d2f3b</td>\n",
       "      <td>0.766519</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pytorch-training-221209-0011-003-c198c584</td>\n",
       "      <td>0.762780</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pytorch-training-221209-0011-014-194d2e74</td>\n",
       "      <td>0.760452</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pytorch-training-221209-0011-002-91f528d4</td>\n",
       "      <td>0.748577</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pytorch-training-221209-0011-007-e0515402</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pytorch-training-221209-0011-004-0778c592</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              TrainingJobName  FinalObjectiveValue  \\\n",
       "8   pytorch-training-221209-0011-010-d474d283             0.794327   \n",
       "6   pytorch-training-221209-0011-012-713a2cab             0.789217   \n",
       "1   pytorch-training-221209-0011-017-26c875ea             0.788787   \n",
       "13  pytorch-training-221209-0011-005-d9f53221             0.783829   \n",
       "0   pytorch-training-221209-0011-018-bbc1a967             0.782722   \n",
       "7   pytorch-training-221209-0011-011-0a4772df             0.780891   \n",
       "9   pytorch-training-221209-0011-009-67fb584b             0.780385   \n",
       "17  pytorch-training-221209-0011-001-ff4aab66             0.774016   \n",
       "12  pytorch-training-221209-0011-006-da6d3b9e             0.771442   \n",
       "5   pytorch-training-221209-0011-013-14b6c947             0.768171   \n",
       "3   pytorch-training-221209-0011-015-61ec86e2             0.767598   \n",
       "10  pytorch-training-221209-0011-008-90a1fb3f             0.766771   \n",
       "2   pytorch-training-221209-0011-016-0c5d2f3b             0.766519   \n",
       "15  pytorch-training-221209-0011-003-c198c584             0.762780   \n",
       "4   pytorch-training-221209-0011-014-194d2e74             0.760452   \n",
       "16  pytorch-training-221209-0011-002-91f528d4             0.748577   \n",
       "11  pytorch-training-221209-0011-007-e0515402             0.480769   \n",
       "14  pytorch-training-221209-0011-004-0778c592             0.480769   \n",
       "\n",
       "   TrainingJobStatus  \n",
       "8          Completed  \n",
       "6          Completed  \n",
       "1          Completed  \n",
       "13         Completed  \n",
       "0          Completed  \n",
       "7          Completed  \n",
       "9          Completed  \n",
       "17         Completed  \n",
       "12         Completed  \n",
       "5          Completed  \n",
       "3          Completed  \n",
       "10         Completed  \n",
       "2          Completed  \n",
       "15         Completed  \n",
       "4          Completed  \n",
       "16         Completed  \n",
       "11         Completed  \n",
       "14         Completed  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tuner_metrics: pd.DataFrame = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    hyperparameter_tuning_job_name=params.sagemaker_tuning_job_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ").dataframe()\n",
    "\n",
    "tuner_metrics[\"optim\"] = tuner_metrics[\"optim\"].apply(lambda x: x.strip('\"'))\n",
    "\n",
    "tuner_metrics.sort_values(\"FinalObjectiveValue\", ascending=False, inplace=True)\n",
    "tuner_metrics[[\"TrainingJobName\", \"FinalObjectiveValue\", \"TrainingJobStatus\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can sort the results by the `FinalObjectiveValue` metric and see the best hyperparameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adam_beta1': 0.9944095815441554,\n",
       " 'adam_beta2': 0.8750000522553327,\n",
       " 'adam_epsilon': 1.8526084265228802e-07,\n",
       " 'label_smoothing_factor': 0.047566123672759336,\n",
       " 'learning_rate': 3.952388499692274e-05,\n",
       " 'optim': 'adafactor',\n",
       " 'weight_decay': 0.1,\n",
       " 'TrainingJobName': 'pytorch-training-221209-0011-010-d474d283',\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'FinalObjectiveValue': 0.794326901435852,\n",
       " 'TrainingStartTime': Timestamp('2022-12-09 00:50:47-0300', tz='tzlocal()'),\n",
       " 'TrainingEndTime': Timestamp('2022-12-09 01:07:13-0300', tz='tzlocal()'),\n",
       " 'TrainingElapsedTimeSeconds': 986.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_job = tuner_metrics.iloc[0]\n",
    "best_job.to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training best model\n",
    "\n",
    "We will train the model using the best hyperparameters found.\n",
    "\n",
    "We will concatenate the training and validation datasets to train the model with more data and evaluate it using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2022-12-23-02-48-36-811\n"
     ]
    }
   ],
   "source": [
    "estimator.environment = {\n",
    "    \"MLFLOW_TRACKING_URI\": params.mlflow_tracking_uri,\n",
    "    \"MLFLOW_EXPERIMENT_NAME\": params.mlflow_experiment_name,\n",
    "    \"MLFLOW_TRACKING_USERNAME\": params.mlflow_tracking_username,\n",
    "    \"MLFLOW_TRACKING_PASSWORD\": params.mlflow_tracking_password,\n",
    "    \"MLFLOW_TAGS\": params.mlflow_tags,\n",
    "    \"MLFLOW_RUN_ID\": mlflow.active_run().info.run_id,\n",
    "    \"MLFLOW_FLATTEN_PARAMS\": \"True\"\n",
    "}\n",
    "\n",
    "estimator._hyperparameters = {\n",
    "    \"num_train_epochs\": params.num_train_epochs,\n",
    "    \"early_stopping_patience\": params.early_stopping_patience,\n",
    "    \"batch_size\": params.batch_size,\n",
    "    \"seed\": params.seed,\n",
    "    \"concat_validation_set\": \"True\",\n",
    "    \"eval_dataset\": \"test\",\n",
    "    \"adam_beta1\": best_job[\"adam_beta1\"],\n",
    "    \"adam_beta2\": best_job[\"adam_beta2\"],\n",
    "    \"adam_epsilon\": best_job[\"adam_epsilon\"],\n",
    "    \"learning_rate\": best_job[\"learning_rate\"],\n",
    "    \"weight_decay\": best_job[\"weight_decay\"],\n",
    "    \"optim\": best_job[\"optim\"]\n",
    "}\n",
    "\n",
    "estimator.fit(inputs, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 57 checkpoints.\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "API request to endpoint /api/2.0/mlflow/runs/update failed with error code 404 != 200. Response body: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\trajano\\OneDrive - HP Inc\\Doug\\GitHub\\pucrs\\ToChiquinho\\src\\toxicity_target__type_identification.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/trajano/OneDrive%20-%20HP%20Inc/Doug/GitHub/pucrs/ToChiquinho/src/toxicity_target__type_identification.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m remove_checkpoints(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/trajano/OneDrive%20-%20HP%20Inc/Doug/GitHub/pucrs/ToChiquinho/src/toxicity_target__type_identification.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     bucket_name\u001b[39m=\u001b[39mbucket_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/trajano/OneDrive%20-%20HP%20Inc/Doug/GitHub/pucrs/ToChiquinho/src/toxicity_target__type_identification.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     checkpoint_prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39m/checkpoints\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/trajano/OneDrive%20-%20HP%20Inc/Doug/GitHub/pucrs/ToChiquinho/src/toxicity_target__type_identification.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     aws_profile_name\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39maws_profile_name\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/trajano/OneDrive%20-%20HP%20Inc/Doug/GitHub/pucrs/ToChiquinho/src/toxicity_target__type_identification.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/trajano/OneDrive%20-%20HP%20Inc/Doug/GitHub/pucrs/ToChiquinho/src/toxicity_target__type_identification.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m mlflow\u001b[39m.\u001b[39;49mend_run()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\mlflow\\tracking\\fluent.py:394\u001b[0m, in \u001b[0;36mend_run\u001b[1;34m(status)\u001b[0m\n\u001b[0;32m    392\u001b[0m env\u001b[39m.\u001b[39munset_variable(_RUN_ID_ENV_VAR)\n\u001b[0;32m    393\u001b[0m run \u001b[39m=\u001b[39m _active_run_stack\u001b[39m.\u001b[39mpop()\n\u001b[1;32m--> 394\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mset_terminated(run\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mrun_id, status)\n\u001b[0;32m    395\u001b[0m _last_active_run_id \u001b[39m=\u001b[39m run\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\mlflow\\tracking\\client.py:1513\u001b[0m, in \u001b[0;36mMlflowClient.set_terminated\u001b[1;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_terminated\u001b[39m(\n\u001b[0;32m   1471\u001b[0m     \u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, status: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, end_time: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1473\u001b[0m     \u001b[39m\"\"\"Set a run's status to terminated.\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m \n\u001b[0;32m   1475\u001b[0m \u001b[39m    :param status: A string value of :py:class:`mlflow.entities.RunStatus`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1511\u001b[0m \u001b[39m        status: KILLED\u001b[39;00m\n\u001b[0;32m   1512\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1513\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mset_terminated(run_id, status, end_time)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:462\u001b[0m, in \u001b[0;36mTrackingServiceClient.set_terminated\u001b[1;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[0;32m    460\u001b[0m end_time \u001b[39m=\u001b[39m end_time \u001b[39mif\u001b[39;00m end_time \u001b[39melse\u001b[39;00m get_current_time_millis()\n\u001b[0;32m    461\u001b[0m status \u001b[39m=\u001b[39m status \u001b[39mif\u001b[39;00m status \u001b[39melse\u001b[39;00m RunStatus\u001b[39m.\u001b[39mto_string(RunStatus\u001b[39m.\u001b[39mFINISHED)\n\u001b[1;32m--> 462\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mupdate_run_info(\n\u001b[0;32m    463\u001b[0m     run_id,\n\u001b[0;32m    464\u001b[0m     run_status\u001b[39m=\u001b[39;49mRunStatus\u001b[39m.\u001b[39;49mfrom_string(status),\n\u001b[0;32m    465\u001b[0m     end_time\u001b[39m=\u001b[39;49mend_time,\n\u001b[0;32m    466\u001b[0m     run_name\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    467\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:148\u001b[0m, in \u001b[0;36mRestStore.update_run_info\u001b[1;34m(self, run_id, run_status, end_time, run_name)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m\"\"\"Updates the metadata of the specified run.\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(\n\u001b[0;32m    140\u001b[0m     UpdateRun(\n\u001b[0;32m    141\u001b[0m         run_uuid\u001b[39m=\u001b[39mrun_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     )\n\u001b[0;32m    147\u001b[0m )\n\u001b[1;32m--> 148\u001b[0m response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(UpdateRun, req_body)\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m RunInfo\u001b[39m.\u001b[39mfrom_proto(response_proto\u001b[39m.\u001b[39mrun_info)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:56\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body)\u001b[0m\n\u001b[0;32m     54\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[0;32m     55\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[1;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:280\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     response \u001b[39m=\u001b[39m http_request(\n\u001b[0;32m    278\u001b[0m         host_creds\u001b[39m=\u001b[39mhost_creds, endpoint\u001b[39m=\u001b[39mendpoint, method\u001b[39m=\u001b[39mmethod, json\u001b[39m=\u001b[39mjson_body\n\u001b[0;32m    279\u001b[0m     )\n\u001b[1;32m--> 280\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[0;32m    281\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[0;32m    282\u001b[0m parse_dict(js_dict\u001b[39m=\u001b[39mjs_dict, message\u001b[39m=\u001b[39mresponse_proto)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:212\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[1;34m(response, endpoint)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m         base_msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAPI request to endpoint \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m failed with error code \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m != 200\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m    209\u001b[0m             endpoint,\n\u001b[0;32m    210\u001b[0m             response\u001b[39m.\u001b[39mstatus_code,\n\u001b[0;32m    211\u001b[0m         )\n\u001b[1;32m--> 212\u001b[0m         \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    213\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Response body: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (base_msg, response\u001b[39m.\u001b[39mtext),\n\u001b[0;32m    214\u001b[0m             error_code\u001b[39m=\u001b[39mget_error_code(response\u001b[39m.\u001b[39mstatus_code),\n\u001b[0;32m    215\u001b[0m         )\n\u001b[0;32m    217\u001b[0m \u001b[39m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m# response\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39mif\u001b[39;00m endpoint\u001b[39m.\u001b[39mstartswith(_REST_API_PATH_PREFIX) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n",
      "\u001b[1;31mMlflowException\u001b[0m: API request to endpoint /api/2.0/mlflow/runs/update failed with error code 404 != 200. Response body: ''"
     ]
    }
   ],
   "source": [
    "remove_checkpoints(\n",
    "    bucket_name=bucket_name,\n",
    "    checkpoint_prefix=f\"{prefix}/checkpoints\",\n",
    "    aws_profile_name=params.aws_profile_name\n",
    ")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "- [Estimators — sagemaker documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)\n",
    "- [HyperparameterTuner — sagemaker documentation](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html)\n",
    "- [Configure and Launch a Hyperparameter Tuning Job - Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-ex-tuning-job.html)\n",
    "- [Managed Spot Training in Amazon SageMaker - Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

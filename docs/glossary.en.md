---
title: Glossary
summary: A glossary of terms used in the Toxicity Detection project.
---

Many different terms are used in the literature that we need to know about. This page is a collection of terms definitions that are used in the Toxicity Detection project.

## Kinds of Offensive Language

### Hate Speech

A type of speech that is used to attack a group of people.[^1]

### Cyberbullying

A type of speech that is used to attack an individual directly.[^1]

## Categories

### Identity Attack

Negative or hateful comments targeting someone because of their identity.[^2]

### Insult

Insulting, inflammatory, or negative comment towards a person or a group of people.[^2]

### Profanity (a.k.a obscene)

Swear words, curse words, or other obscene or profane language.[^2]

### Racism

Prejudiced thoughts and discriminatory actions based on difference in race/ethnicity.[^3]

### Religious intolerance

Pending

### Sexism

Prejudiced thoughts and discriminatory actions based on difference in sex/gender, usually by men against women (a.k.a misogyny).[^3]

### Xenophobia

The fear or hatred of foreigners.[^3]

[^1]: Zampieri et al. "Predicting the type and target of offensive posts in social media." NAACL 2019.
[^2]: "Perspective | Developers", Developers.perspectiveapi.com, 2021. [Online]. Available: https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages. [Accessed: 21- Aug- 2021]
[^3]: Washington University - Student Affairs. (2020, August 12). Glossary of bias terms. Students. https://students.wustl.edu/glossary-bias-terms/.